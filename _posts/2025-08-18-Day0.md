---
title: "Aletheia: Automated AI safety testing platform"
date: 2025-08-18
categories: [Aletheia]
---

# Building an automated AI saftey testing platform

For the next few months, I will be working **Aletheia**, a comprehensive AI safety platform that automatically tests, monitors, and evaluates AI models for alignment issues across multiple dimensions: truthfulness, helpfulness, harmlessness, and value alignment with continuous safety monitoring, red-teaming automation, and interpretability insights to ensure responsible AI deployment at scale.

I'm planning to utilize FastAPI and Python for the backend to call AI models with Together AI API calls, and React for a frontend web development.

I envision users selecting an AI model of their choice where the platform will automatically conduct safety tests (including jailbreaks, red-teaming, etc) to produce a comprehensive report on the model's safety.

# Development

Today, I started out with installing relevant dependancies for Together AI API calls and building a simple technical architecture

```bash
pip3 install together openai requests

```

<img width="229" height="280" alt="Screenshot 2025-08-18 at 12 11 41â€¯PM" src="https://github.com/user-attachments/assets/1c92bc44-63e6-4b85-8008-c8786b4afe1a" />
